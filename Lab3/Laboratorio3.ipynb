{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAxmXdRmQBmHv8M0qDbkIe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RosalesLuis123/IA/blob/main/Lab3/Laboratorio3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conectamos a drive**"
      ],
      "metadata": {
        "id": "MY7FFLj0OjiW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-Za4LOdWFG_",
        "outputId": "8815bbaa-8819-4948-9316-de8c2280e370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importamos las librerias**"
      ],
      "metadata": {
        "id": "rAGSGUxiOvFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utilizado para la manipulación de directorios y rutas\n",
        "import os\n",
        "\n",
        "# Cálculo científico y vectorial para python\n",
        "import numpy as np\n",
        "\n",
        "# Libreria para graficos\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# Modulo de optimizacion en scipy\n",
        "from scipy import optimize\n",
        "\n",
        "# modulo para cargar archivos en formato MATLAB\n",
        "# from scipy.io import loadmat\n",
        "\n",
        "# le dice a matplotlib que incruste gráficos en el cuaderno\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "WRtPkoy2WHYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Leemos el data set a la par de que le indicamos la cantidad de columnas y clases que tendra, seleccionamos las columnas que usaremos**"
      ],
      "metadata": {
        "id": "wdTUemQkPCWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Definir input_layer_size y num_labels\n",
        "input_layer_size = 12\n",
        "num_labels = 3\n",
        "\n",
        "# Cargar datos desde el archivo CSV utilizando pandas\n",
        "data_df = pd.read_csv('/content/gdrive/MyDrive/Laboratorio3/walmart.txt', delimiter=',')\n",
        "\n",
        "# Seleccionar las columnas necesarias\n",
        "selected_columns = ['Size', 'Unemployment', 'CPI', 'Fuel_Price', 'Temperature',\n",
        "                    'Weekly_Sales', 'Dept', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'Type']\n",
        "\n",
        "data_df = data_df[selected_columns]\n",
        "\n",
        "# Convertir el DataFrame de pandas a arrays de NumPy\n",
        "data = data_df.to_numpy()\n",
        "\n",
        "# Obtener características (X) y etiquetas (y)\n",
        "X = data[:, :-1]  # Todas las columnas excepto la última (Type)\n",
        "y = data[:, -1]  # Tomar la última columna (Type) como y\n",
        "\n",
        "# Número de muestras\n",
        "m = y.size\n"
      ],
      "metadata": {
        "id": "o20hrXYtWPZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imprimir Matrices**"
      ],
      "metadata": {
        "id": "iuZ6XxKBPPfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0,:])\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Bl1nNjbbeRR",
        "outputId": "06abb166-f62c-4ffa-bc35-b0d9e351d123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.51315000e+05 8.10600000e+00 2.11096358e+02 2.57200000e+00\n",
            " 4.23100000e+01 2.49245000e+04 1.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00]\n",
            "[3. 3. 3. ... 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hacemos uso de la formula de la normalizacion, para que los valores sean utililizables**"
      ],
      "metadata": {
        "id": "TgfqPWkYPnSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def  featureNormalize(X):\n",
        "    X_norm = X.copy()\n",
        "    mu = np.zeros(X.shape[1])\n",
        "    sigma = np.zeros(X.shape[1])\n",
        "\n",
        "    mu = np.mean(X, axis = 0)\n",
        "    sigma = np.std(X, axis = 0)\n",
        "    X_norm = (X - mu) / sigma\n",
        "\n",
        "    return X_norm, mu, sigma"
      ],
      "metadata": {
        "id": "2dkAw55xblBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llama featureNormalize con los datos cargados\n",
        "X_norm, mu, sigma = featureNormalize(X)"
      ],
      "metadata": {
        "id": "N8BqDnMSczQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar la matriz adecuadamente, y agregar una columna de unos que corresponde al termino de intercepción.\n",
        "m, n = X.shape\n",
        "# Agraga el termino de intercepción a A\n",
        "# X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)\n",
        "X = X_norm\n",
        "# X = np.concatenate([np.ones((m, 1)), X], axis=1)"
      ],
      "metadata": {
        "id": "8wmHixvyc1g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualizacion de datos**"
      ],
      "metadata": {
        "id": "_NJbfMLlP5IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def displayData(X, example_width=None, figsize=(10, 10)):\n",
        "    if X.ndim == 2:\n",
        "        m, n = X.shape\n",
        "    elif X.ndim == 1:\n",
        "        n = X.size\n",
        "        m = 1\n",
        "        X = X[None]\n",
        "    else:\n",
        "        raise IndexError('La entrada X debe ser 1 o 2 dimensinal.')\n",
        "\n",
        "    example_width = example_width or int(np.round(np.sqrt(n)))\n",
        "    example_height = n / example_width\n",
        "\n",
        "    display_rows = int(np.floor(np.sqrt(m)))\n",
        "    display_cols = int(np.ceil(m / display_rows))\n",
        "\n",
        "    fig, ax_array = pyplot.subplots(display_rows, display_cols, figsize=figsize)\n",
        "    fig.subplots_adjust(wspace=0.025, hspace=0.025)\n",
        "\n",
        "    ax_array = [ax_array] if m == 1 else ax_array.ravel()\n",
        "\n",
        "    for i, ax in enumerate(ax_array):\n",
        "        ax.imshow(X[i].reshape(example_width, example_width, order='F'),\n",
        "                  cmap='Greys', extent=[0, 1, 0, 1])\n",
        "        ax.axis('off')\n"
      ],
      "metadata": {
        "id": "Il6pvfFPc3QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecciona aleatoriamente 100 puntos de datos para mostrar\n",
        "rand_indices = np.random.choice(m, 100, replace=False)\n",
        "sel = X[rand_indices, :]\n",
        "\n",
        "# displayData(sel)"
      ],
      "metadata": {
        "id": "tSPOVc1xdGFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Se calcula la sigmoide**"
      ],
      "metadata": {
        "id": "iqB8FbfdQCHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Calcula la sigmoide de z.\n",
        "    \"\"\"\n",
        "    return 1.0 / (1.0 + np.exp(-z))"
      ],
      "metadata": {
        "id": "jh5Xw7eWdKd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Se Hace uso de la funcion del costo**"
      ],
      "metadata": {
        "id": "C49C1xFDQLV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lrCostFunction(theta, X, y, lambda_):\n",
        "    \"\"\"\n",
        "    Calcula el costo de usar theta como parámetro para la regresión logística regularizada y\n",
        "    el gradiente del costo w.r.t. a los parámetros.\n",
        "\n",
        "    Parametros\n",
        "    ----------\n",
        "    theta : array_like\n",
        "        Parametro theta de la regresion logistica. Vector de la forma(shape) (n, ). n es el numero de caracteristicas\n",
        "        incluida la intercepcion\n",
        "\n",
        "    X : array_like\n",
        "        Dataset con la forma(shape) (m x n). m es el numero de ejemplos, y n es el numero de\n",
        "        caracteristicas (incluida la intercepcion).\n",
        "\n",
        "    y : array_like\n",
        "        El conjunto de etiquetas. Un vector con la forma (shape) (m, ). m es el numero de ejemplos\n",
        "\n",
        "    lambda_ : float\n",
        "        Parametro de regularización.\n",
        "\n",
        "    Devuelve\n",
        "    -------\n",
        "    J : float\n",
        "        El valor calculado para la funcion de costo regularizada.\n",
        "\n",
        "    grad : array_like\n",
        "        Un vector de la forma (shape) (n, ) que es el gradiente de la\n",
        "        función de costo con respecto a theta, en los valores actuales de theta..\n",
        "    \"\"\"\n",
        "#     alpha = 0.003\n",
        "#     theta = theta.copy()\n",
        "    # Inicializa algunos valores utiles\n",
        "    m = y.size\n",
        "\n",
        "    # convierte las etiquetas a valores enteros si son boleanos\n",
        "    if y.dtype == bool:\n",
        "        y = y.astype(int)\n",
        "\n",
        "    J = 0\n",
        "    grad = np.zeros(theta.shape)\n",
        "\n",
        "    h = sigmoid(X.dot(theta.T))\n",
        "\n",
        "    temp = theta\n",
        "    temp[0] = 0\n",
        "\n",
        "#     J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n",
        "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
        "\n",
        "    grad = (1 / m) * (h - y).dot(X)\n",
        "#     theta = theta - (alpha / m) * (h - y).dot(X)\n",
        "    grad = grad + (lambda_ / m) * temp\n",
        "\n",
        "    return J, grad\n",
        "#    return J, theta"
      ],
      "metadata": {
        "id": "onH9xGYndOEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **clasificación de uno contra todos mediante el entrenamiento de múltiples clasificadores de regresión logística regularizados**"
      ],
      "metadata": {
        "id": "tMlJgq4AQaur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def oneVsAll(X, y, num_labels, lambda_):\n",
        "    \"\"\"\n",
        "    Trains num_labels logistic regression classifiers and returns\n",
        "    each of these classifiers in a matrix all_theta, where the i-th\n",
        "    row of all_theta corresponds to the classifier for label i.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array_like\n",
        "        The input dataset of shape (m x n). m is the number of\n",
        "        data points, and n is the number of features. Note that we\n",
        "        do not assume that the intercept term (or bias) is in X, however\n",
        "        we provide the code below to add the bias term to X.\n",
        "\n",
        "    y : array_like\n",
        "        The data labels. A vector of shape (m, ).\n",
        "\n",
        "    num_labels : int\n",
        "        Number of possible labels.\n",
        "\n",
        "    lambda_ : float\n",
        "        The logistic regularization parameter.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    all_theta : array_like\n",
        "        The trained parameters for logistic regression for each class.\n",
        "        This is a matrix of shape (K x n+1) where K is number of classes\n",
        "        (ie. `numlabels`) and n is number of features without the bias.\n",
        "    \"\"\"\n",
        "    # algunas variables utiles\n",
        "    m, n = X.shape\n",
        "\n",
        "    all_theta = np.zeros((num_labels, n + 1))\n",
        "\n",
        "    # Agrega unos a la matriz X\n",
        "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
        "\n",
        "    for c in np.arange(num_labels):\n",
        "        initial_theta = np.zeros(n + 1)\n",
        "        options = {'maxiter': 50}\n",
        "        res = optimize.minimize(lrCostFunction,\n",
        "                                initial_theta,\n",
        "                                (X, (y == c), lambda_),\n",
        "                                jac=True,\n",
        "                                method='CG',\n",
        "                                options=options)\n",
        "\n",
        "        all_theta[c] = res.x\n",
        "\n",
        "    return all_theta"
      ],
      "metadata": {
        "id": "hHjTMwKYdQIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_ = 0.1\n",
        "all_theta = oneVsAll(X, y, num_labels, lambda_)\n",
        "print(all_theta.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJoVpHeudSuL",
        "outputId": "67f59f32-0e02-4ea9-ded2-a21bb1871a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3fYCkbMdU4n",
        "outputId": "76dc4254-c80a-4906-823a-be59006dd7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.24380805e+01 -4.79305765e-15  1.53441691e-15 -8.59084926e-16\n",
            "  -6.07742108e-15  3.54722687e-15 -3.27854272e-15 -9.40864029e-16\n",
            "  -7.23602505e-15 -4.17227728e-15 -1.14837711e-15]\n",
            " [-1.25004714e+01 -7.47783507e+00  1.08448964e+00 -3.14172933e-01\n",
            "   3.39918718e-01 -3.51636727e-01  3.30643933e-01  2.29466194e-02\n",
            "  -2.85635609e+00 -6.24772120e-01 -7.83601889e-01]\n",
            " [-6.02153773e-01 -1.14000536e+00 -1.32155321e-01 -2.04222724e-01\n",
            "   6.67696669e-02 -3.23585527e-01 -6.53912916e-02 -7.91168592e-02\n",
            "   1.70933201e-01 -1.51020593e-02  2.99395283e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediccion One-vs-all**"
      ],
      "metadata": {
        "id": "C185O9dPQkn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predictOneVsAll(all_theta, X):\n",
        "    \"\"\"\n",
        "    Devuelve un vector de predicciones para cada ejemplo en la matriz X.\n",
        "    Tenga en cuenta que X contiene los ejemplos en filas.\n",
        "    all_theta es una matriz donde la i-ésima fila es un vector theta de regresión logística entrenada para la i-ésima clase.\n",
        "    Debe establecer p en un vector de valores de 0..K-1 (por ejemplo, p = [0, 2, 0, 1]\n",
        "    predice clases 0, 2, 0, 1 para 4 ejemplos).\n",
        "\n",
        "    Parametros\n",
        "    ----------\n",
        "    all_theta : array_like\n",
        "        The trained parameters for logistic regression for each class.\n",
        "        This is a matrix of shape (K x n+1) where K is number of classes\n",
        "        and n is number of features without the bias.\n",
        "\n",
        "    X : array_like\n",
        "        Data points to predict their labels. This is a matrix of shape\n",
        "        (m x n) where m is number of data points to predict, and n is number\n",
        "        of features without the bias term. Note we add the bias term for X in\n",
        "        this function.\n",
        "\n",
        "    Devuelve\n",
        "    -------\n",
        "    p : array_like\n",
        "        The predictions for each data point in X. This is a vector of shape (m, ).\n",
        "    \"\"\"\n",
        "\n",
        "    m = X.shape[0];\n",
        "    num_labels = all_theta.shape[0]\n",
        "\n",
        "    p = np.zeros(m)\n",
        "\n",
        "    # Add ones to the X data matrix\n",
        "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
        "    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n",
        "\n",
        "    return p"
      ],
      "metadata": {
        "id": "8my9NbmSdW6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "pred = predictOneVsAll(all_theta, X)\n",
        "print('Precision del conjuto de entrenamiento: {:.2f}%'.format(np.mean(pred == y) * 100))\n",
        "XPrueba = X[10:150, :].copy()\n",
        "print(XPrueba.shape)\n",
        "#print(np.ones((1)))\n",
        "#print(XPrueba)\n",
        "#p = np.zeros(1)\n",
        "XPrueba = np.concatenate([np.ones((140, 1)), XPrueba], axis=1)\n",
        "print(XPrueba.shape)\n",
        "p = np.argmax(sigmoid(XPrueba.dot(all_theta.T)), axis = 1)\n",
        "print(p)\n",
        "\n",
        "# displayData(X[1002:1003, :])\n",
        "print(y[10:150])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INTebS9mddeR",
        "outputId": "d600dcaf-587e-427a-923c-79a36eef1e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(421570, 10)\n",
            "Precision del conjuto de entrenamiento: 42.71%\n",
            "(140, 10)\n",
            "(140, 11)\n",
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "[3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
            " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
            " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
            " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
            " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
            " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Para concluir pudimos apreciar que el modelo tiene una precision de 42.71%, lo cual nos da a entender que no es fiable para predecir.**"
      ],
      "metadata": {
        "id": "WORUZhfMQyyt"
      }
    }
  ]
}